{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0ada9fabe7e6e53f306d2de459e56a9ae70b3c90146f086e5031f9817e1f8397e",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StansdardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import gower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNImputerProcess(path, max_min=None):\n",
    "    df = pd.read_csv(path)\n",
    "    id = df[\"id\"]\n",
    "    df = df.drop([\"id\", \"height\"], axis=1)\n",
    "\n",
    "    #bmi\n",
    "    for i in range(len(df['bmi'])):\n",
    "        if df['bmi'][i] >= 45:\n",
    "            df['bmi'][i] = 30.0\n",
    "    \n",
    "    #marriage\n",
    "    marriage_mapping = {'No': 0, 'Yes': 1}\n",
    "    df['ever_married'] = df['ever_married'].map(marriage_mapping)\n",
    "\n",
    "    #one_hot encoder for ...\n",
    "    categorical_features_oh = ['gender', 'blood', 'smoking_status', 'Residence_type', 'work_type']\n",
    "    for i in categorical_features_oh:\n",
    "        df[i] = pd.Categorical(df[i])\n",
    "        dfDummies = pd.get_dummies(df[i], prefix= i)\n",
    "        df = pd.concat([df, dfDummies], axis=1)\n",
    "    for i in categorical_features_oh:\n",
    "        df.drop(columns=i, axis=1, inplace=True)\n",
    "    \n",
    "    flag = False\n",
    "    #normalize\n",
    "    if max_min == None:\n",
    "        flag = True\n",
    "        max_min = {}\n",
    "        norm_feature = ['age', 'avg_glucose_level', 'bmi']\n",
    "        for i in norm_feature:\n",
    "            max = np.nanmax(df[i].to_numpy())\n",
    "            min = np.nanmin(df[i].to_numpy())\n",
    "            max_min[i] = [max, min]\n",
    "            n = max - min\n",
    "            for j in range(len(df[i])):\n",
    "                df[i][j] = (df[i][j] - min)/n\n",
    "    else:\n",
    "        norm_feature = ['age', 'avg_glucose_level', 'bmi']\n",
    "        for i in norm_feature:\n",
    "            max = max_min[i][0]\n",
    "            min = max_min[i][1]\n",
    "            n = max - min\n",
    "            for j in range(len(df[i])):\n",
    "                if df[i][j] < min:\n",
    "                    df[i][j] = 0\n",
    "                elif df[i][j] > max:\n",
    "                    df[i][j] = 1\n",
    "                else: df[i][j] = (df[i][j] - min)/n\n",
    "    \n",
    "    col = df.columns\n",
    "    imputer = KNNImputer(n_neighbors=20)\n",
    "    imputer.fit(df)\n",
    "    df = imputer.transform(df)\n",
    "    df = pd.DataFrame(df, columns=col)\n",
    "\n",
    "    df = pd.concat([df, id], axis=1)\n",
    "    if flag == True:\n",
    "        return df, max_min\n",
    "    else: return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-77-5d52ce94a3b9>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['bmi'][i] = 30.0\n<ipython-input-77-5d52ce94a3b9>:36: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[i][j] = (df[i][j] - min)/n\n"
     ]
    }
   ],
   "source": [
    "df_train, max_min = KNNImputerProcess('./Dataset/train.csv')\n",
    "df_train = df_train.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4000 entries, 0 to 3999\nData columns (total 26 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   age                             4000 non-null   float64\n 1   hypertension                    4000 non-null   float64\n 2   heart_disease                   4000 non-null   float64\n 3   ever_married                    4000 non-null   float64\n 4   avg_glucose_level               4000 non-null   float64\n 5   bmi                             4000 non-null   float64\n 6   stroke                          4000 non-null   float64\n 7   gender_Female                   4000 non-null   float64\n 8   gender_Male                     4000 non-null   float64\n 9   gender_Other                    4000 non-null   float64\n 10  blood_A                         4000 non-null   float64\n 11  blood_AB                        4000 non-null   float64\n 12  blood_B                         4000 non-null   float64\n 13  blood_O                         4000 non-null   float64\n 14  smoking_status_Unknown          4000 non-null   float64\n 15  smoking_status_formerly smoked  4000 non-null   float64\n 16  smoking_status_never smoked     4000 non-null   float64\n 17  smoking_status_smokes           4000 non-null   float64\n 18  Residence_type_Rural            4000 non-null   float64\n 19  Residence_type_Unknown          4000 non-null   float64\n 20  Residence_type_Urban            4000 non-null   float64\n 21  work_type_Govt_job              4000 non-null   float64\n 22  work_type_Never_worked          4000 non-null   float64\n 23  work_type_Private               4000 non-null   float64\n 24  work_type_Self-employed         4000 non-null   float64\n 25  work_type_children              4000 non-null   float64\ndtypes: float64(26)\nmemory usage: 812.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "source": [
    "MODEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import lightgbm as gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train.drop([\"stroke\"], axis=1).to_numpy()\n",
    "y = df_train[\"stroke\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_smt = SVMSMOTE()\n",
    "tl = TomekLinks(sampling_strategy='majority')\n",
    "resample = Pipeline([('smt', svm_smt), ('tl', tl)])\n",
    "x_new, y_new = resample.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Thresh= 0\n",
      "0.9876024948080249\n",
      "Thresh= 0\n",
      "0.9876024948080249\n",
      "Thresh= 100\n",
      "0.9876024948080249\n",
      "Thresh= 108\n",
      "0.9870866737703224\n",
      "Thresh= 201\n",
      "0.9873447624546108\n",
      "Thresh= 201\n",
      "0.9873447624546108\n",
      "Thresh= 212\n",
      "0.9873513754330034\n",
      "Thresh= 219\n",
      "0.9870999615970855\n",
      "Thresh= 220\n",
      "0.9881166570809569\n",
      "Thresh= 223\n",
      "0.9883773695203336\n",
      "Thresh= 232\n",
      "0.9879862824728569\n",
      "Thresh= 254\n",
      "0.9888767968330562\n",
      "Thresh= 266\n",
      "0.9893979643474863\n",
      "Thresh= 285\n",
      "0.9881233172728144\n",
      "Thresh= 289\n",
      "0.986826582087876\n",
      "Thresh= 291\n",
      "0.9850140510513354\n",
      "Thresh= 298\n",
      "0.9856531656363217\n",
      "Thresh= 325\n",
      "0.9828104326233605\n",
      "Thresh= 353\n",
      "0.9764928444858881\n",
      "Thresh= 419\n",
      "0.9768520226255071\n",
      "Thresh= 495\n",
      "0.9710898389524267\n",
      "Thresh= 1040\n",
      "0.9644000520366923\n",
      "Thresh= 2444\n",
      "0.9522375612135209\n",
      "Thresh= 2574\n",
      "0.9449786474441136\n",
      "Thresh= 2650\n",
      "0.9382947807071398\n"
     ]
    }
   ],
   "source": [
    "model = gbm.LGBMClassifier(boosting='gbdt', max_depth=-1, n_estimators=500)\n",
    "model.fit(x_new, y_new)\n",
    "thresholds = np.sort(model.booster_.feature_importance())\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "scoring = ['f1']\n",
    "scores = cross_validate(model, x, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "max = np.mean(scores['test_f1'])\n",
    "best_transform = None\n",
    "best_model = model\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(x_new)\n",
    "    # train model\n",
    "    selection_model = gbm.LGBMClassifier(boosting='gbdt', max_depth=-1, n_estimators=500)\n",
    "    selection_model.fit(select_X_train, y_new)\n",
    "\t# eval model\n",
    "    scores2 = cross_validate(selection_model, select_X_train, y_new, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "    print(\"Thresh=\", (thresh))\n",
    "    print(np.mean(scores2['test_f1']))\n",
    "    if np.mean(scores2['test_f1']) > max:\n",
    "        max = np.mean(scores2['test_f1'])\n",
    "        best_model = selection_model\n",
    "        best_transform = selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_transform != None:\n",
    "    x_new = best_transform.transform(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Best: 0.989636 using {'boosting': 'gbdt', 'max_depth': 10, 'n_estimators': 500}\n",
      "0.920903 (0.011280) with: {'boosting': 'gbdt', 'max_depth': 2, 'n_estimators': 10}\n",
      "0.964387 (0.005425) with: {'boosting': 'gbdt', 'max_depth': 2, 'n_estimators': 100}\n",
      "0.982144 (0.005239) with: {'boosting': 'gbdt', 'max_depth': 2, 'n_estimators': 500}\n",
      "0.984152 (0.004459) with: {'boosting': 'gbdt', 'max_depth': 2, 'n_estimators': 1000}\n",
      "0.958044 (0.006858) with: {'boosting': 'gbdt', 'max_depth': 5, 'n_estimators': 10}\n",
      "0.985531 (0.004766) with: {'boosting': 'gbdt', 'max_depth': 5, 'n_estimators': 100}\n",
      "0.988901 (0.004704) with: {'boosting': 'gbdt', 'max_depth': 5, 'n_estimators': 500}\n",
      "0.988898 (0.004593) with: {'boosting': 'gbdt', 'max_depth': 5, 'n_estimators': 1000}\n",
      "0.975312 (0.005185) with: {'boosting': 'gbdt', 'max_depth': 10, 'n_estimators': 10}\n",
      "0.987680 (0.004512) with: {'boosting': 'gbdt', 'max_depth': 10, 'n_estimators': 100}\n",
      "0.989636 (0.004270) with: {'boosting': 'gbdt', 'max_depth': 10, 'n_estimators': 500}\n",
      "0.989550 (0.004216) with: {'boosting': 'gbdt', 'max_depth': 10, 'n_estimators': 1000}\n",
      "0.975140 (0.005393) with: {'boosting': 'gbdt', 'max_depth': -1, 'n_estimators': 10}\n",
      "0.987762 (0.004219) with: {'boosting': 'gbdt', 'max_depth': -1, 'n_estimators': 100}\n",
      "0.989633 (0.004342) with: {'boosting': 'gbdt', 'max_depth': -1, 'n_estimators': 500}\n",
      "0.989461 (0.004049) with: {'boosting': 'gbdt', 'max_depth': -1, 'n_estimators': 1000}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 2, 'n_estimators': 10}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 2, 'n_estimators': 100}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 2, 'n_estimators': 500}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 2, 'n_estimators': 1000}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 5, 'n_estimators': 10}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 5, 'n_estimators': 100}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 5, 'n_estimators': 500}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 5, 'n_estimators': 1000}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 10, 'n_estimators': 10}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 10, 'n_estimators': 100}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 10, 'n_estimators': 500}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': 10, 'n_estimators': 1000}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': -1, 'n_estimators': 10}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': -1, 'n_estimators': 100}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': -1, 'n_estimators': 500}\n",
      "0.000000 (0.000000) with: {'boosting': 'rf', 'max_depth': -1, 'n_estimators': 1000}\n",
      "0.918985 (0.010406) with: {'boosting': 'dart', 'max_depth': 2, 'n_estimators': 10}\n",
      "0.951801 (0.005955) with: {'boosting': 'dart', 'max_depth': 2, 'n_estimators': 100}\n",
      "0.972804 (0.005531) with: {'boosting': 'dart', 'max_depth': 2, 'n_estimators': 500}\n",
      "0.979399 (0.005898) with: {'boosting': 'dart', 'max_depth': 2, 'n_estimators': 1000}\n",
      "0.957225 (0.006823) with: {'boosting': 'dart', 'max_depth': 5, 'n_estimators': 10}\n",
      "0.979442 (0.005459) with: {'boosting': 'dart', 'max_depth': 5, 'n_estimators': 100}\n",
      "0.987627 (0.003513) with: {'boosting': 'dart', 'max_depth': 5, 'n_estimators': 500}\n",
      "0.988430 (0.003919) with: {'boosting': 'dart', 'max_depth': 5, 'n_estimators': 1000}\n",
      "0.973748 (0.005621) with: {'boosting': 'dart', 'max_depth': 10, 'n_estimators': 10}\n",
      "0.986494 (0.004518) with: {'boosting': 'dart', 'max_depth': 10, 'n_estimators': 100}\n",
      "0.988945 (0.004211) with: {'boosting': 'dart', 'max_depth': 10, 'n_estimators': 500}\n",
      "0.989199 (0.003827) with: {'boosting': 'dart', 'max_depth': 10, 'n_estimators': 1000}\n",
      "0.974054 (0.005671) with: {'boosting': 'dart', 'max_depth': -1, 'n_estimators': 10}\n",
      "0.986235 (0.004339) with: {'boosting': 'dart', 'max_depth': -1, 'n_estimators': 100}\n",
      "0.989120 (0.004088) with: {'boosting': 'dart', 'max_depth': -1, 'n_estimators': 500}\n",
      "0.989115 (0.004445) with: {'boosting': 'dart', 'max_depth': -1, 'n_estimators': 1000}\n",
      "0.920903 (0.011280) with: {'boosting': 'goss', 'max_depth': 2, 'n_estimators': 10}\n",
      "0.964687 (0.006160) with: {'boosting': 'goss', 'max_depth': 2, 'n_estimators': 100}\n",
      "0.983627 (0.005159) with: {'boosting': 'goss', 'max_depth': 2, 'n_estimators': 500}\n",
      "0.984294 (0.005077) with: {'boosting': 'goss', 'max_depth': 2, 'n_estimators': 1000}\n",
      "0.958044 (0.006858) with: {'boosting': 'goss', 'max_depth': 5, 'n_estimators': 10}\n",
      "0.984726 (0.004716) with: {'boosting': 'goss', 'max_depth': 5, 'n_estimators': 100}\n",
      "0.988299 (0.004340) with: {'boosting': 'goss', 'max_depth': 5, 'n_estimators': 500}\n",
      "0.988430 (0.004698) with: {'boosting': 'goss', 'max_depth': 5, 'n_estimators': 1000}\n",
      "0.975312 (0.005185) with: {'boosting': 'goss', 'max_depth': 10, 'n_estimators': 10}\n",
      "0.987725 (0.004588) with: {'boosting': 'goss', 'max_depth': 10, 'n_estimators': 100}\n",
      "0.988871 (0.004567) with: {'boosting': 'goss', 'max_depth': 10, 'n_estimators': 500}\n",
      "0.988697 (0.004454) with: {'boosting': 'goss', 'max_depth': 10, 'n_estimators': 1000}\n",
      "0.975140 (0.005393) with: {'boosting': 'goss', 'max_depth': -1, 'n_estimators': 10}\n",
      "0.987297 (0.004471) with: {'boosting': 'goss', 'max_depth': -1, 'n_estimators': 100}\n",
      "0.988950 (0.004299) with: {'boosting': 'goss', 'max_depth': -1, 'n_estimators': 500}\n",
      "0.988994 (0.004433) with: {'boosting': 'goss', 'max_depth': -1, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define models and parameters\n",
    "boosting = ['gbdt', 'rf', 'dart', 'goss']\n",
    "n_estimators = [10, 100, 500, 1000]\n",
    "max_depth = [2, 5, 10, -1]\n",
    "# define grid search\n",
    "grid = dict(boosting=boosting, n_estimators=n_estimators, max_depth=max_depth)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='f1',error_score=0)\n",
    "grid_result = grid_search.fit(x_new, y_new)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2356, 1071,  580,  187, 2396, 2293,  211,  378,   94,  186,  270,\n",
       "        178,  339,  250,  388,  402,  336,  317,  189,  227,  150,    0,\n",
       "        242,  278,    0])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "best_model.booster_.feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gbm.LGBMClassifier(boosting='gbdt', max_depth=-1, n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='gbdt', n_estimators=500)"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "best_model.fit(x_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-88-eb82f7d5953f>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['bmi'][i] = 30.0\n<ipython-input-88-eb82f7d5953f>:48: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  else: df[i][j] = (df[i][j] - min)/n\n"
     ]
    }
   ],
   "source": [
    "df_test = KNNImputerProcess('./Dataset/public_test.csv', max_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = df_test['id'].to_numpy()\n",
    "x_test = df_test.drop(['id'], axis=1).to_numpy()\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_transform != None:\n",
    "    x_test = best_transform.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_xgb_pred_test = best_model.predict(x_test)\n",
    "data_test_submit = {'id': id_test, 'stroke': y_xgb_pred_test}\n",
    "df_test_submit = pd.DataFrame(data= data_test_submit)\n",
    "df_test_submit\n",
    "df_test_submit.to_csv('./Submission/Submission_lgbm.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(500, 13)"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "x_test.shape"
   ]
  }
 ]
}